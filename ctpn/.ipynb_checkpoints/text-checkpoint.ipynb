{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像数据\n",
    "img = cv2.imread('1.jpg')\n",
    "# label数据，好像有几个类\n",
    "label = {\n",
    "    \"boxes\":[[100, 100, 200, 300]],\n",
    "    \"label\": 1,\n",
    "    \"image_id\": 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 333, 500])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = []\n",
    "img.append(cv2.imread('1.jpg'))\n",
    "img = torch.LongTensor(img).permute(0, 3, 1, 2).float()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "backbone = resnet_fpn_backbone('resnet50', False)\n",
    "output = backbone(img)\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPNhead(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, num_anchors):\n",
    "        super(RPNhead, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, in_channels, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.cls_logits = nn.Conv2d(\n",
    "            in_channels, num_anchors, kernel_size=1, stride=1\n",
    "        )\n",
    "        self.bbox_pred = nn.Conv2d(\n",
    "            in_channels, num_anchors * 4, kernel_size=1, stride=1\n",
    "        )\n",
    "\n",
    "        # init parameters\n",
    "        for l in self.children():\n",
    "            torch.nn.init.normal_(l.weight, std=0.01)\n",
    "            torch.nn.init.constant_(l.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入的是feature_map, feature_map有可能是多层(resnet)\n",
    "        # x: C * [batch_size, out_channel, H_out, W_out]\n",
    "        features = list(x.values())\n",
    "        logits = []\n",
    "        bbox_reg = []\n",
    "        for feature in features:\n",
    "            t = nn.functional.relu(self.conv(feature))\n",
    "            logits.append(self.cls_logits(t))\n",
    "            bbox_reg.append(self.bbox_pred(t))\n",
    "        return bbox_reg, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channel = backbone.out_channels\n",
    "Anchor_sizes = (16, 64, 128)\n",
    "aspect_ratios = (0.5, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_head = RPNhead(input_channel, len(Anchor_sizes) * len(aspect_ratios))\n",
    "bbox_reg, logits = rpn_head(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 256, 84, 125]),\n",
       " torch.Size([1, 256, 42, 63]),\n",
       " torch.Size([1, 256, 21, 32]),\n",
       " torch.Size([1, 256, 11, 16]),\n",
       " torch.Size([1, 256, 6, 8])]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成anchor的各个中心点\n",
    "# 已知feature_map有5层\n",
    "[i.shape for i in output.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每层feature_map的尺寸\n",
    "feature_size = [i.shape[-2:] for i in output.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取输入图片的尺寸\n",
    "img_size = img.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([84, 125]), torch.Size([42, 63]), torch.Size([21, 32]), torch.Size([11, 16]), torch.Size([6, 8])]\n",
      "torch.Size([333, 500])\n"
     ]
    }
   ],
   "source": [
    "print(feature_size)\n",
    "print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算每层的stride\n",
    "stride = torch.LongTensor([[img_size[0]//f[0], img_size[1]//f[1]] for f in feature_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3,  4],\n",
      "        [ 7,  7],\n",
      "        [15, 15],\n",
      "        [30, 31],\n",
      "        [55, 62]])\n"
     ]
    }
   ],
   "source": [
    "print(stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这样的话我们就可以生成,每个anchor的中心点\n",
    "centers = []\n",
    "for f, s in zip(feature_size, stride):\n",
    "    y = torch.arange(0, f[0]) * s[0]\n",
    "    x = torch.arange(0, f[1]) * s[1]\n",
    "    y, x = torch.meshgrid(y,x)\n",
    "    y = y.reshape(-1)\n",
    "    x = x.reshape(-1)\n",
    "    center = torch.stack((y,x,y,x), dim = 1)\n",
    "    centers.append(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([10500, 4]),\n",
       " torch.Size([2646, 4]),\n",
       " torch.Size([672, 4]),\n",
       " torch.Size([176, 4]),\n",
       " torch.Size([48, 4])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(centers))\n",
    "[i.shape for i in centers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成每个anchor的长宽\n",
    "# Anchor_sizes = (16, 64, 128)\n",
    "# aspect_ratios = (0.5, 1, 2)\n",
    "Anchor_scales = torch.as_tensor(Anchor_sizes, dtype = torch.float32)\n",
    "aspect_ratios = torch.as_tensor(aspect_ratios, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ratios = torch.sqrt(aspect_ratios)\n",
    "w_ratios = 1/h_ratios\n",
    "\n",
    "ws = h_ratios[:, None] * Anchor_scales[None, :].view(-1)\n",
    "hs = w_ratios[:, None] * Anchor_scales[None, :].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_anchor = torch.stack([-ws, -hs, ws, hs], dim = 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -5.6569, -22.6274, -45.2548],\n",
       "         [-11.3137, -45.2548, -90.5097],\n",
       "         [  5.6569,  22.6274,  45.2548],\n",
       "         [ 11.3137,  45.2548,  90.5097]],\n",
       "\n",
       "        [[ -8.0000, -32.0000, -64.0000],\n",
       "         [ -8.0000, -32.0000, -64.0000],\n",
       "         [  8.0000,  32.0000,  64.0000],\n",
       "         [  8.0000,  32.0000,  64.0000]],\n",
       "\n",
       "        [[-11.3137, -45.2548, -90.5097],\n",
       "         [ -5.6569, -22.6274, -45.2548],\n",
       "         [ 11.3137,  45.2548,  90.5097],\n",
       "         [  5.6569,  22.6274,  45.2548]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
